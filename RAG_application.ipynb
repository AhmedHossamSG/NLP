{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e1310dd-4770-4c41-b80f-e6fce0975acb",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b021b602-25c8-4493-b7b5-103c4c59a1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed packages\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# for openai access \n",
    "import openai\n",
    "from langchain_community.llms import OpenAI \n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# work with URL laoder as example \n",
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "# store data in vector database\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# history of chat\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# for loading keys\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from uuid_extensions import uuid7, uuid7str\n",
    "\n",
    "# for gradio interface \n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c3c087-870c-4cdf-b1c9-35d9a33bf109",
   "metadata": {},
   "source": [
    "## Loading Enviroment Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7920e10b-1643-4def-8bdc-f32633f0c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"keys.env\")\n",
    "\n",
    "# Access the secret key from environment variables\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10382f8e-328b-4636-9024-bf4805295ba0",
   "metadata": {},
   "source": [
    "## Intializing LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75482fce-b52d-4f1d-9181-a7cfa77d7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049b25b2",
   "metadata": {},
   "source": [
    "### Collect data from websites URLs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a095762e-aad6-4850-901f-7849a9010082",
   "metadata": {},
   "outputs": [],
   "source": [
    "greek_compus_url = 'https://www.thegreekcampus.com/'\n",
    "MQR_url = 'https://www.mqrspaces.com/'\n",
    "\n",
    "places_urls = [greek_compus_url, MQR_url]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483478ff-eb82-4a6a-b8e0-40a8aac4bc6a",
   "metadata": {},
   "source": [
    "## Creating a Vectorestore from URLs Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe0cf02-8391-40d3-8a27-d32fde23841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for url in  places_urls : \n",
    "    loaders = UnstructuredURLLoader(urls=[url])\n",
    "    data.append(loaders.load()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d811b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.thegreekcampus.com/'}, page_content='Where groundbreaking\\n\\nstartups and tech companies\\n\\nconnect, collaborate and create.\\n\\nAt A\\xa0Glance\\n\\n12\\n\\nYEARS FOSTERING\\n\\nINNOVATION\\n\\nENTREPRENEURSHIP HUBS IN CAIRO\\n\\n250+\\n\\nSTARTUPS & CORPORATES\\n\\n2,800\\n\\nMEMBERS IN HIGH-IMPACT JOBS\\n\\n200\\n\\nINDUSTRY-LEADING EVENTS HOSTED\\n\\n25\\n\\nINVESTMENT ROUNDS\\n\\nA hub for homegrown innovation where businesses at all stages join together to develop and grow new ideas.\\n\\nThe essence of The GrEEK Campus that formulates its unique DNA lies in three essential elements: its connected support network, its collaborative spaces, and the real heart of the campus — its creative community.\\n\\nOur Community\\n\\nThis is the ideal space to grow your community.\\n\\nCommunity is why we\\'re here and it\\'s what we\\'re most proud of.\\n\\nOur Journey So Far\\n\\n2013\\n\\nTHE COMMUNITY BUILT FROM THE GROUND UP\\n\\nOur Chairman & Founder, Mr. Ahmed El Alfi, kickstarts the transformation of the abandoned complex into a vibrant entrepreneurial hub with impactful community development at the core.\\n\\n2014\\n\\nTHE GREEK CAMPUS GOES VIRAL IN THE MEDIA\\n\\n\"Cairo\\'s GrEEK Campus Underscores Egypt\\'s Tech Revolution\"\\n\\nWSJ\\n\\n\"New tech park launches in Tahrir Square\"\\n\\nwamda\\n\\n\"Tahrir Square Finds a GrEEK Neighbour\"\\n\\nIPS News\\n\\n2015\\n\\nKEY INDUSTRY PLAYERS DRAWN BY OUR POWER OF BRAND\\n\\nMicrosoft, TrendMicro, PWC, Uber, Aramex, MO4 Network, GESR Program\\n\\n2016\\n\\nGROWING STRONG: OCCUPANCY HITS RECORD HIGH\\u200b\\n\\nSecret sauce to our success?\\n\\n“To be the coolest and most fun place to work and create in the Arab world”\\n\\nAhmed Alfi, Chairman and Founder of The GrEEK Campus\\n\\n2017\\n\\nBUILDING LOCAL & GLOBAL SYNERGIES\\u200b\\n\\nHosting the most prominent entrepreneurial events and competitions making waves in the MENA region\\n\\n2018\\n\\nAMPLIFYING THE VOICES OF CAIRO CREATIVES\\u200b\\n\\nThe hub transforms at night to platform Cairo’s cultural and creative scene with first-of-its-kind festivals.\\n\\n2019\\n\\nSETTING THE STANDARD\\u200b\\n\\nSpectacular spaces that inspire creativity in every corner. TrendMicro\\'s workspace and hall museum on campus receives the Golden Award in the International A’Design Award and Competition.\\n\\n2020\\n\\nA NEW ALL-IN-ONE HUB IN WEST CAIRO\\u200b\\n\\nTo meet growing demands of our flourishing entrepreneurial community, The GrEEK Campus West opens its doors in December 2020.'),\n",
       " Document(metadata={'source': 'https://www.mqrspaces.com/'}, page_content=\"WORK FROM MQR SPACES\\n\\nImpressively modern facilities and networking opportunities make MQR the perfect space for you and your venture.\\n\\nBecome a\\xa0Member\\n\\nOUR LOCATIONS\\n\\nWe're closer to you than ever\\n\\nDowntown\\xa0-\\xa0Maadi\\xa0-\\xa0October\\xa0-\\xa0Zayed\\xa0-\\xa0Al Rabwa\\xa0-\\xa0New Cairo\\xa0-\\xa0Cairo Business Park\\xa0-\\xa0Al Rehab\\xa0-\\xa0El Gouna\\xa0- Menofia - Aswan\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNew Cairo\\n\\nAl Rehab\\n\\nExplore\\n\\nZayed\\n\\nEden Mall\\n\\nExplore\\n\\nDowntown\\n\\nThe GrEEK Campus\\n\\nExplore\\n\\nNew Cairo\\n\\nPlatz\\n\\nExplore\\n\\nOctober\\n\\nMelanite Mall\\n\\nExplore\\n\\nMaadi\\n\\nEco Building\\n\\nExplore\\n\\nZayed\\n\\nAl Rabwa\\n\\nExplore\\n\\nNew Cairo\\n\\nCairo Business Park\\n\\nExplore\\n\\nEl Gouna\\n\\nGSpace\\n\\nExplore\\n\\nNext\\n\\nOUR SERVICES\\n\\nOur services cater to the different needs of entrepreneurs and business owners, from meeting rooms and \\nprivate offices to\\xa0training venues and shared spaces.\\n\\nPrivate Offices\\n\\nGet your own private office to take your work-life up a notch.\\n\\nShared Spaces\\n\\nGrab\\xa0a desk in one of our shared areas to be more productive.\\n\\nMeeting Rooms\\n\\nBook your meeting room at our spaces to manage your day better.\\n\\nTraining Rooms\\n\\nHold your trainings at our spaces to ensure all\\xa0your needs are taken care of.\\n\\nLearn More\\n\\nOUR AMENITIES\\n\\nWe know exactly what it takes to get a business off the ground. That’s why we built a state-of-the-art workspace where you can focus on your next big project.\\n\\nCommunity Care Team\\n\\nAlways available\\n\\nFlexible Setup\\n\\nDesigning your preferred\\xa0layout\\n\\nCleaning Services\\n\\nProtecting your wellbeing\\n\\nHigh-Speed Internet\\n\\nEnabling your success\\n\\nEvents & Meetups\\n\\nDeveloping your skills and network\\n\\nPrinters\\n\\nPrinting your important\\xa0documents\\n\\nFood & Beverages\\n\\nKeeping you up to the task\\n\\nLockers\\n\\nKeeping your belongings\\xa0safe\\n\\nSecurity System\\n\\nSecuring the premises via camera\\n\\nOUR COMMUNITY\\n\\nIN COLLABORATION WITH\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the gathered data \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fec81efe-e792-4a46-8c1b-81011d9fa8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of creating data just read it uncomment if you want to create it\n",
    "\n",
    "# this part for creating v_db\n",
    "vectorstore = Chroma.from_documents(documents=data, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f553c",
   "metadata": {},
   "source": [
    "### RAG application with system prompt only ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe81133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 250+ startups at The GrEEK Campus.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "# Define the RAG chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "# Ask a question and get a response\n",
    "query = \"How many startups are in the greek compus?\"\n",
    "response = rag_chain.run(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653a776f-3d12-4051-befc-fc03ad1eef28",
   "metadata": {},
   "source": [
    "## Creating History Aware Retriever ( RAG + chat history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "226b1bd7-e4fe-4635-8d63-213ef3186907",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = (\n",
    "    \"\"\"Given a chat history and the latest user question\n",
    "    which might reference context in the chat history,\n",
    "    formulate a response which can be understood and clear\n",
    "    without the chat history. Do NOT answer the question,\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# contextualize\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# add chat history\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0246e3-356b-41d0-82b1-4d7be4cc88e6",
   "metadata": {},
   "source": [
    "## System prompt retrieveral "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "514bb6c1-316a-4692-9d6e-268cfba66ed6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bot_system_prompts/ICN system prompt.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m system_prompt\n\u001b[1;32m     12\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbot_system_prompts/ICN system prompt.txt\u001b[39m\u001b[38;5;124m'\u001b[39m  \n\u001b[0;32m---> 13\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m \u001b[43mread_system_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m, in \u001b[0;36mread_system_prompt\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_system_prompt\u001b[39m(file_path):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      3\u001b[0m         prompt_content \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      5\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{context}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/ivy_dev/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bot_system_prompts/ICN system prompt.txt'"
     ]
    }
   ],
   "source": [
    "def read_system_prompt(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        prompt_content = file.read()\n",
    "\n",
    "    context = \"{context}\"\n",
    "\n",
    "    system_prompt = f'(\"\"\"\\n{prompt_content.strip()}\\n\"\"\"\\n\"{context}\")'\n",
    "\n",
    "    return system_prompt\n",
    "\n",
    "\n",
    "file_path = 'add your path'  \n",
    "system_prompt = read_system_prompt(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b981690-1882-4f0b-b610-88f09525312c",
   "metadata": {},
   "source": [
    "## Q_A_chain Creation and invoking it in RAG Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1afa0a34-ab3a-4c02-9459-cb7b15643de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a8405a0-924c-4511-b2b2-35edaef7962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f021ad0a-6879-4f5a-98f0-327a267ae286",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e3581f-0634-49fd-916b-69cdd28471c8",
   "metadata": {},
   "source": [
    "## Session History Retrieveral Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77f37e48-330e-4d91-b781-0b9e8fdeaa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c7a944-98d6-4ac2-ae00-6af7b181743d",
   "metadata": {},
   "source": [
    "## Creating Conversational RAG chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbe9ff67-5670-4f3d-906e-0fe8b976ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final conversational RAG chain\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    "    max_tokens_limit=500,\n",
    "    top_n=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8ed272-53f7-4dcf-afe6-334fca48ca2a",
   "metadata": {},
   "source": [
    "## Running Chat Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f70156ad-6325-418f-ae08-220e445c4c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Runchat(user_input, session_id):\n",
    "    print(\"ICNBot: \", end=\"\")\n",
    "    # Use the session_id dynamically\n",
    "    response = conversational_rag_chain.invoke({\"input\": user_input}, config={\"configurable\": {\"session_id\": session_id}})[\"answer\"]\n",
    "    return response, \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf68ae-70d5-4634-9c99-cb8ba8df181a",
   "metadata": {},
   "source": [
    "## Creating User Interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "732fef79-819b-4c7d-9a15-f31e1430dd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:8082\n",
      "Running on public URL: https://23ebbb0af5bcb90b15.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://23ebbb0af5bcb90b15.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run ebbdbcef-6883-41e9-bab0-35eacdf2cc43 not found for run 44065f3b-9afe-461d-865c-113b7d24281f. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICNBot: "
     ]
    }
   ],
   "source": [
    "def create_gradio_interface():\n",
    "    with gr.Blocks() as demo:\n",
    "        chatbot = gr.Chatbot(height=240)\n",
    "        msg = gr.Textbox(label=\"Prompt\")\n",
    "        btn = gr.Button(\"Send\")\n",
    "        clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "        # Generate a unique session ID for each user session\n",
    "        session_id = str(uuid7())  # Generates a unique session ID\n",
    "\n",
    "        # Function to handle responses\n",
    "        def respond(user_input, chatbot):\n",
    "            response, _ = Runchat(user_input, session_id)  # Pass session_id to Runchat\n",
    "            chatbot.append((user_input, response))\n",
    "            return \"\", chatbot\n",
    "\n",
    "        # Button click and message submit events\n",
    "        btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "        msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])  # Press enter to submit\n",
    "\n",
    "    gr.close_all()\n",
    "    demo.queue().launch(share=True, server_port=8082)\n",
    "\n",
    "# Run the interface creation function\n",
    "if __name__ == \"__main__\":\n",
    "    create_gradio_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8b54c03-9661-4eaa-a5f7-ad819ab5ea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.close_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
